---
layout: post
title:  "ä¸€ä¸ªåŸºäº LangChain 1.0 å’Œ Streamlit çš„æ™ºèƒ½è¿ç»´åŠ©æ‰‹"
date:   2025-11-03 18:12:00 +0800
tags:
  - LangChain
  - rag
  - llm
---
# ä½¿ç”¨ langchain 1.0 (Agent, Tools + RAG) + æœ¬åœ°å¤§æ¨¡å‹ + æœ¬åœ°åµŒå…¥å‘é‡å¼€å‘


ä¸€ä¸ªåŸºäº LangChain 1.0 å’Œ Streamlit çš„æ™ºèƒ½è¿ç»´åŠ©æ‰‹ï¼Œä½¿ç”¨ Agent é›†æˆäº† RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯å’Œ func tools call èƒ½åŠ›ã€‚é‡‡ç”¨ Ollama æœ¬åœ°å¤§æ¨¡å‹ï¼Œæ— éœ€ API å¯†é’¥ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€äº¤äº’å¤„ç†è¿ç»´ä»»åŠ¡ã€‚
é¡¹ç›®åœ°å€: [ai_ops_assistant_agent](https://github.com/pluckhuang/ai_ops_assistant_agent)

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– **æ™ºèƒ½å¯¹è¯ç•Œé¢** - åŸºäº Streamlit çš„å‹å¥½äº¤äº’ç•Œé¢
- ğŸ§  **æœ¬åœ°å¤§æ¨¡å‹** - ä½¿ç”¨ Ollama (llama3.2:3b)ï¼Œæ— éœ€ API è°ƒç”¨è´¹ç”¨
- ğŸ“Š **AWS ç›‘æ§** - CloudWatch é›†æˆï¼Œå®æ—¶æŸ¥è¯¢ EC2 CPU ä½¿ç”¨ç‡
-  **RAG æ–‡æ¡£æ£€ç´¢** - FAISS å‘é‡æ•°æ®åº“ + LCEL é“¾å¼è°ƒç”¨
- ğŸ”§ **å¯æ‰©å±•å·¥å…·ç³»ç»Ÿ** - åŸºäº LangChain Agent çš„å·¥å…·è°ƒç”¨æ¡†æ¶
- ğŸ¯ **å¤šæ¨¡å‹æ”¯æŒ** - æ”¯æŒ Ollama/OpenAI/AWS Bedrock/DeepSeek

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Streamlit å‰ç«¯ (app.py)         â”‚
â”‚          èŠå¤©ç•Œé¢ + ç”¨æˆ·äº¤äº’             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LangChain Agent (agent_runner.py)  â”‚
â”‚      ChatOllama + create_agent          â”‚
â”‚      æ ¹æ®ç”¨æˆ·é—®é¢˜æ™ºèƒ½é€‰æ‹©å·¥å…·            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚
        â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG Tool      â”‚    â”‚ AWS CloudWatch Toolâ”‚
â”‚ (qa_chain)    â”‚    â”‚ (get_ec2_cpu_usage)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚
        â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS Index   â”‚    â”‚   AWS API          â”‚
â”‚ + Embeddings  â”‚    â”‚   boto3 Client     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒç»„ä»¶è¯´æ˜ï¼š**
- **app.py**: Streamlit UIï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥è¾“å‡º
- **agent_runner.py**: Agent æ‰§è¡Œå™¨ï¼Œåè°ƒå·¥å…·è°ƒç”¨
- **tools.py**: å·¥å…·å®šä¹‰ï¼ˆAWS ç›‘æ§ã€æ–‡æ¡£æ£€ç´¢ï¼‰
- **rag_chain.py**: RAG é“¾å®ç°ï¼ˆLCEL è¯­æ³•ï¼‰
- **llm_factory.py**: å¤šæ¨¡å‹æ”¯æŒçš„ LLM å·¥å‚
- **embedding_factory.py**: åµŒå…¥æ¨¡å‹å·¥å‚ï¼ˆOllama/OpenAI/æœ¬åœ°ï¼‰
- **vectorstore_manager.py**: FAISS å‘é‡å­˜å‚¨ç®¡ç†

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.11+
- **Ollama**: æœ¬åœ°å®‰è£…ï¼ˆç”¨äºå¤§æ¨¡å‹å’ŒåµŒå…¥ï¼‰
- **AWS å‡­è¯**: ï¼ˆå¯é€‰ï¼‰ç”¨äº CloudWatch ç›‘æ§åŠŸèƒ½

### 1. å®‰è£… Ollama

```bash
# macOS
brew install ollama

# å¯åŠ¨ Ollama æœåŠ¡
ollama serve
```

### 2. ä¸‹è½½æ‰€éœ€æ¨¡å‹

```bash
# è¿è¡Œè‡ªåŠ¨åŒ–è„šæœ¬
chmod +x setup_ollama.sh
./setup_ollama.sh

# æˆ–æ‰‹åŠ¨ä¸‹è½½
ollama pull llama3.2:3b
ollama pull nomic-embed-text
```

### 3. å®‰è£… Python ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3.11 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 4. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# AWS é…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äº CloudWatch åŠŸèƒ½ï¼‰
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_DEFAULT_REGION=us-east-1

# OpenAI é…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äºåˆ‡æ¢æ¨¡å‹ï¼‰
OPENAI_API_KEY=your_openai_api_key

# DeepSeek é…ç½®ï¼ˆå¯é€‰ï¼‰
DEEPSEEK_API_KEY=your_deepseek_api_key

# æ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼‰
DB_URI=mysql+pymysql://user:password@localhost/dbname
```

### 5. åˆå§‹åŒ–å‘é‡æ•°æ®åº“

```bash
# å°†æ–‡æ¡£æ”¾å…¥ data/ ç›®å½•
# è¿è¡Œå‘é‡åŒ–è„šæœ¬ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨åˆ›å»ºï¼‰
python vectorstore_manager.py
```

### 6. è¿è¡Œåº”ç”¨

```bash
streamlit run app.py
```

è®¿é—® `http://localhost:8501` å³å¯ä½¿ç”¨ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
ai_ops_assistant/
â”œâ”€â”€ app.py                    # Streamlit ä¸»åº”ç”¨
â”œâ”€â”€ agent_runner.py           # Agent æ‰§è¡Œå™¨ï¼ˆChatOllama + toolsï¼‰
â”œâ”€â”€ rag_chain.py             # RAG é“¾å®ç°ï¼ˆLCEL è¯­æ³•ï¼‰
â”œâ”€â”€ tools.py                 # å·¥å…·å®šä¹‰ï¼ˆAWS + QAï¼‰
â”œâ”€â”€ llm_factory.py           # LLM å·¥å‚ï¼ˆå¤šæ¨¡å‹æ”¯æŒï¼‰
â”œâ”€â”€ embedding_factory.py     # Embedding å·¥å‚ï¼ˆOllama/OpenAI/Localï¼‰
â”œâ”€â”€ vectorstore_manager.py   # FAISS å‘é‡å­˜å‚¨ç®¡ç†
â”œâ”€â”€ config.yaml              # å…¨å±€é…ç½®æ–‡ä»¶
â”œâ”€â”€ setup_ollama.sh          # Ollama æ¨¡å‹ä¸‹è½½è„šæœ¬
â”œâ”€â”€ requirements.txt         # Python ä¾èµ–
â”œâ”€â”€ pyproject.toml           # é¡¹ç›®é…ç½®ï¼ˆBlack/isort/flake8ï¼‰
â”œâ”€â”€ .pre-commit-config.yaml  # ä»£ç è´¨é‡æ£€æŸ¥
â”œâ”€â”€ .env                     # ç¯å¢ƒå˜é‡ï¼ˆä¸æäº¤åˆ° Gitï¼‰
â”œâ”€â”€ data/                    # æ–‡æ¡£æ•°æ®ç›®å½•
â”‚   â””â”€â”€ sample.txt
â”œâ”€â”€ faiss_index/             # FAISS ç´¢å¼•å­˜å‚¨
â”‚   â””â”€â”€ ollama/
â”‚       â””â”€â”€ index.faiss
â””â”€â”€ db/                      # æ•°æ®åº“ç›¸å…³
    â””â”€â”€ init.sql
```

## ğŸ› ï¸ ä¸»è¦ç»„ä»¶è¯¦è§£

### 1. Agent Runner (`agent_runner.py`)
```python
# ä½¿ç”¨ LangChain çš„ create_agent åˆ›å»º Agent
agent_runner = create_agent(
    ChatOllama(model="llama3.2:3b"),
    tools=[get_ec2_cpu_usage, qa_chain_tool],
    system_prompt="..."
)
```
- **æ¨¡å‹**: ChatOllama (llama3.2:3b)
- **å·¥å…·**: AWS CloudWatch + RAG æ–‡æ¡£æ£€ç´¢
- **ç­–ç•¥**: æ ¹æ®ç”¨æˆ·é—®é¢˜è‡ªåŠ¨é€‰æ‹©åˆé€‚å·¥å…·

### 2. RAG Chain (`rag_chain.py`)
```python
# LCEL è¯­æ³•æ„å»º RAG é“¾
chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```
- **æŠ€æœ¯**: LangChain Expression Language (LCEL)
- **å‘é‡åº“**: FAISS
- **åµŒå…¥æ¨¡å‹**: Ollama (nomic-embed-text)

### 3. AWS CloudWatch Tool (`tools.py`)
```python
@tool(args_schema=AwsCpuCheckInput)
def get_ec2_cpu_usage(instance_id: str, hours: int = 1):
    """æŸ¥è¯¢ EC2 å®ä¾‹çš„ CPU ä½¿ç”¨ç‡"""
    # ä½¿ç”¨ boto3 è°ƒç”¨ CloudWatch API
```
- **åŠŸèƒ½**: æŸ¥è¯¢ EC2 å®ä¾‹ CPU ä½¿ç”¨ç‡
- **å‚æ•°**: instance_idï¼ˆå¿…éœ€ï¼‰ã€hoursï¼ˆé»˜è®¤ 1 å°æ—¶ï¼‰
- **è®¤è¯**: ä» `.env` è¯»å– AWS å‡­è¯

### 4. å¤šæ¨¡å‹æ”¯æŒ (`llm_factory.py`)
```python
def get_llm(provider="ollama", model_name="llama3.2:3b", temperature=0.2):
    if provider == "ollama": return ChatOllama(...)
    elif provider == "openai": return ChatOpenAI(...)
    elif provider == "aws": return ChatBedrock(...)
    # ...
```
æ”¯æŒçš„æ¨¡å‹æä¾›å•†ï¼š
- **Ollama** (é»˜è®¤): æœ¬åœ°å…è´¹ï¼Œæ—  API è°ƒç”¨
- **OpenAI**: GPT-3.5/4
- **AWS Bedrock**: Claude ç­‰æ¨¡å‹
- **DeepSeek**: å›½å†… API

### 5. Embedding Factory (`embedding_factory.py`)
```python
def get_embeddings(provider="local"):
    if provider == "ollama": return OllamaEmbeddings(...)
    elif provider == "openai": return OpenAIEmbeddings(...)
    else: return LocalEmbeddings(...)  # SentenceTransformer fallback
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### æŸ¥è¯¢ EC2 CPU ä½¿ç”¨ç‡
```
ç”¨æˆ·: æŸ¥è¯¢å®ä¾‹ i-1234567890abcdef0 æœ€è¿‘ 2 å°æ—¶çš„ CPU ä½¿ç”¨ç‡
åŠ©æ‰‹: [è°ƒç”¨ get_ec2_cpu_usage å·¥å…·]
      å®ä¾‹ i-1234567890abcdef0 åœ¨æœ€è¿‘ 2 å°æ—¶çš„å¹³å‡ CPU ä½¿ç”¨ç‡ä¸º 45.2%
```

### æ–‡æ¡£æ£€ç´¢é—®ç­”
```
ç”¨æˆ·: å¦‚ä½•é…ç½® AWS Security Groupï¼Ÿ
åŠ©æ‰‹: [è°ƒç”¨ qa_chain_toolï¼Œä»å‘é‡åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£]
      æ ¹æ®æ–‡æ¡£ï¼Œé…ç½® Security Group çš„æ­¥éª¤åŒ…æ‹¬...
```

### è‡ªç„¶è¯­è¨€æ··åˆæŸ¥è¯¢
```
ç”¨æˆ·: æˆ‘çš„æœåŠ¡å™¨ CPU çªç„¶å‡é«˜äº†ï¼Œæœ‰ä»€ä¹ˆæ’æŸ¥å»ºè®®å—ï¼Ÿ
åŠ©æ‰‹: [Agent è‡ªåŠ¨ç»„åˆå¤šä¸ªå·¥å…·]
      1. [CloudWatch Tool] å½“å‰ CPU ä½¿ç”¨ç‡ä¸º 85%
      2. [RAG Tool] æ ¹æ®è¿ç»´æ‰‹å†Œï¼Œå»ºè®®æ£€æŸ¥...
```

## âš™ï¸ é…ç½®è¯´æ˜

### `config.yaml` é…ç½®é¡¹
```yaml
llm_provider: "ollama"          # LLM æä¾›å•†
model_name: "llama3"           # æ¨¡å‹åç§°
temperature: 0.2               # æ¸©åº¦å‚æ•°

embedding_options: ["local", "openai"]  # å¯ç”¨çš„åµŒå…¥æ¨¡å‹
embedding_model_local: "all-mpnet-base-v2"
embedding_model_openai: "text-embedding-3-small"
```

### åˆ‡æ¢æ¨¡å‹æä¾›å•†
ä¿®æ”¹ `agent_runner.py`:
```python
# ä½¿ç”¨ OpenAI
from langchain_openai import ChatOpenAI
chat_model = ChatOpenAI(model="gpt-4", temperature=0)

# ä½¿ç”¨ AWS Bedrock
from langchain_aws import ChatBedrock
chat_model = ChatBedrock(model_id="anthropic.claude-3-sonnet-20240229-v1:0")
```

## ğŸ”§ å¼€å‘å·¥å…·

### ä»£ç è´¨é‡æ£€æŸ¥
```bash
# å®‰è£… pre-commit hooks
pre-commit install

# æ‰‹åŠ¨è¿è¡Œæ£€æŸ¥
pre-commit run --all-files
```

é…ç½®äº†ä»¥ä¸‹å·¥å…·ï¼š
- **autoflake**: ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥
- **isort**: å¯¼å…¥æ’åº
- **black**: ä»£ç æ ¼å¼åŒ–
- **flake8**: ä»£ç é£æ ¼æ£€æŸ¥

### è°ƒè¯•æ¨¡å¼
```bash
# æŸ¥çœ‹ Agent æ‰§è¡Œæ—¥å¿—
export LANGCHAIN_TRACING_V2=true
streamlit run app.py
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issues å’Œ Pull Requestsï¼

## ğŸ“„ è®¸å¯è¯

MIT License

---

**æ³¨æ„**: é¦–æ¬¡è¿è¡Œå‰è¯·ç¡®ä¿ï¼š
1. âœ… Ollama æœåŠ¡å·²å¯åŠ¨ (`ollama serve`)
2. âœ… å·²ä¸‹è½½æ‰€éœ€æ¨¡å‹ (`./setup_ollama.sh`)
3. âœ… AWS å‡­è¯å·²é…ç½®ï¼ˆå¦‚éœ€ä½¿ç”¨ CloudWatch åŠŸèƒ½ï¼‰
4. âœ… æ–‡æ¡£å·²æ”¾å…¥ `data/` ç›®å½•å¹¶åˆå§‹åŒ–å‘é‡åº“